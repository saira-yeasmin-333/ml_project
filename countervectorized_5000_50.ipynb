{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7651011,"sourceType":"datasetVersion","datasetId":4460288},{"sourceId":7654107,"sourceType":"datasetVersion","datasetId":4462327},{"sourceId":7654996,"sourceType":"datasetVersion","datasetId":4462951}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport torch\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score,roc_auc_score\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import StandardScaler\nimport nltk\nimport os\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\n\ndata_read = pd.read_csv('../input/mlprocesseddata/data_with_target.csv')\n\n# Separate X and y\nX_read = data_read.drop(columns=['popular']).values\ny_read = data_read['popular'].values\n\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(X_read, y_read, test_size=0.2, random_state=42)\n\n# Standardize the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Convert to PyTorch tensors\nX_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train[:, None], dtype=torch.float32)  # Reshape y to [n_samples, 1]\nX_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\ny_test_tensor = torch.tensor(y_test[:, None], dtype=torch.float32)\n\n# Create TensorDatasets and DataLoaders\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntest_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Define the neural network architecture\nclass SimpleNN(nn.Module):\n    def __init__(self, input_size):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(input_size, 64)\n        self.fc2 = nn.Linear(64, 64)\n        self.fc3 = nn.Linear(64, 1)\n        self.relu = nn.ReLU()\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, x):\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        x = self.sigmoid(self.fc3(x))\n        return x\n\n# Initialize the model and move it to GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('device: ',device)\nmodel = SimpleNN(input_size=X_train_tensor.shape[1]).to(device)\n\n# Define the loss function and optimizer\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Train the model\nnum_epochs = 50\nfor epoch in range(num_epochs):\n    model.train()\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        # Forward pass\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        \n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n\n# Test the model\nmodel.eval()\nwith torch.no_grad():\n    y_pred = model(X_test_tensor.to(device)).cpu().numpy()\n    y_pred = np.round(y_pred).flatten()\n\n# Calculate accuracy, precision, and recall\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nroc = roc_auc_score(y_test, y_pred)\n\nprint(f'Accuracy: {accuracy}')\nprint(f'Precision: {precision}')\nprint(f'Recall: {recall}')\nprint(f'ROC_AUC: {roc}')\n","metadata":{"execution":{"iopub.status.busy":"2024-02-19T11:06:49.880777Z","iopub.execute_input":"2024-02-19T11:06:49.881581Z","iopub.status.idle":"2024-02-19T11:07:10.880332Z","shell.execute_reply.started":"2024-02-19T11:06:49.881547Z","shell.execute_reply":"2024-02-19T11:07:10.879444Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"device:  cuda\nEpoch [1/50], Loss: 0.6549\nEpoch [2/50], Loss: 0.5923\nEpoch [3/50], Loss: 0.5789\nEpoch [4/50], Loss: 0.5621\nEpoch [5/50], Loss: 0.6114\nEpoch [6/50], Loss: 0.6523\nEpoch [7/50], Loss: 0.6446\nEpoch [8/50], Loss: 0.6818\nEpoch [9/50], Loss: 0.5819\nEpoch [10/50], Loss: 0.6042\nEpoch [11/50], Loss: 0.6410\nEpoch [12/50], Loss: 0.6442\nEpoch [13/50], Loss: 0.5377\nEpoch [14/50], Loss: 0.5984\nEpoch [15/50], Loss: 0.5767\nEpoch [16/50], Loss: 0.5804\nEpoch [17/50], Loss: 0.6088\nEpoch [18/50], Loss: 0.5292\nEpoch [19/50], Loss: 0.4698\nEpoch [20/50], Loss: 0.6015\nEpoch [21/50], Loss: 0.5493\nEpoch [22/50], Loss: 0.5659\nEpoch [23/50], Loss: 0.5339\nEpoch [24/50], Loss: 0.7462\nEpoch [25/50], Loss: 0.4759\nEpoch [26/50], Loss: 0.5433\nEpoch [27/50], Loss: 0.5717\nEpoch [28/50], Loss: 0.5533\nEpoch [29/50], Loss: 0.5560\nEpoch [30/50], Loss: 0.5514\nEpoch [31/50], Loss: 0.6359\nEpoch [32/50], Loss: 0.6510\nEpoch [33/50], Loss: 0.7094\nEpoch [34/50], Loss: 0.5716\nEpoch [35/50], Loss: 0.6596\nEpoch [36/50], Loss: 0.6159\nEpoch [37/50], Loss: 0.6464\nEpoch [38/50], Loss: 0.5778\nEpoch [39/50], Loss: 0.5205\nEpoch [40/50], Loss: 0.6178\nEpoch [41/50], Loss: 0.5995\nEpoch [42/50], Loss: 0.6056\nEpoch [43/50], Loss: 0.6545\nEpoch [44/50], Loss: 0.5010\nEpoch [45/50], Loss: 0.5531\nEpoch [46/50], Loss: 0.5169\nEpoch [47/50], Loss: 0.6604\nEpoch [48/50], Loss: 0.5794\nEpoch [49/50], Loss: 0.5668\nEpoch [50/50], Loss: 0.6123\nAccuracy: 0.679\nPrecision: 0.6732394366197183\nRecall: 0.5382882882882883\nROC_AUC: 0.6648275973815543\n","output_type":"stream"}]}]}